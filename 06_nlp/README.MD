# 06_nlp — NLP / LLM Projects

Раздел с проектами по обработке естественного языка: от классического ML на TF-IDF до BERT и прикладных LLM-пайплайнов (разметка, краткие резюме, кластеризация карточек).

## Содержание

| Проект | Файл | Задача | Подход | Результат/метрики |
|---|---|---|---|---|
| Классификация токсичных комментариев (TF-IDF) | `Классификация токсичных комментариев (TF-IDF).ipynb` | Детекция токсичности | TF-IDF + Logistic Regression/Linear models, подбор порога | **F1 (val best)** ≈ **0.815** |
| Классификация токсичных комментариев (BERT) | `Классификация токсичных комментариев (BERT).ipynb` | Детекция токсичности | Transformers/BERT, подбор порога | **F1 (val best)** ≈ **0.843**, **ROC-AUC** ≈ **0.985** |
| NLP-аналитика отзывов (тональность/аспекты/резюме) | `NLP-аналитика отзывов - тональность, аспекты и резюме (LLM, Qwen).ipynb` | Разметка отзывов + краткие summaries | LLM (Qwen), prompt-pipeline | Авторазметка по полям `sentiment/aspect/summary` |
| Кластеризация товаров продавца | `Кластеризация товаров продавца.ipynb` | Группировка карточек по смыслу | Embeddings + UMAP + HDBSCAN/DBSCAN + LLM-enrich | Кластеры + визуализации + интерпретация |

---

## 1) Классификация токсичных комментариев (TF-IDF)

**Файл:** `Классификация токсичных комментариев (TF-IDF).ipynb`

**Цель:** построить baseline-модель, которая определяет токсичные комментарии.

**Что сделано:**
- очистка и нормализация текста, базовая предобработка;
- векторизация **TF-IDF**;
- обучение и сравнение линейных моделей;
- подбор **порога классификации** под F1 (а не только дефолт 0.5);
- оценка качества и разбор ошибок.

**Ключевой результат:**
- **F1 (best on validation)** ≈ **0.815** (с подбором порога)

---

## 2) Классификация токсичных комментариев (BERT)

**Файл:** `Классификация токсичных комментариев (BERT).ipynb`

**Цель:** улучшить качество по сравнению с классическим TF-IDF baseline.

**Что сделано:**
- пайплайн на Transformers/BERT;
- получение вероятностей + **подбор оптимального порога** под F1;
- отчёты по метрикам и quality-check.

**Ключевые метрики (validation):**
- **F1 (best)** ≈ **0.843**
- **Accuracy** ≈ **0.970**
- **ROC-AUC** ≈ **0.985**
- **PR-AUC (AP)** ≈ **0.924**

**Вывод:** BERT даёт заметный прирост качества относительно TF-IDF baseline.

---

## 3) NLP-аналитика отзывов: тональность, аспекты и резюме (LLM/Qwen)

**Файл:** `NLP-аналитика отзывов - тональность, аспекты и резюме (LLM, Qwen).ipynb`

**Цель:** построить прикладной NLP-пайплайн для анализа отзывов без ручной разметки.

**Подход:** LLM (Qwen) автоматически размечает каждый отзыв по 3 полям:
- `sentiment`: **positive / neutral / negative**
- `aspect`: **quality / price / delivery / service / other**
- `summary`: короткое резюме (5–15 слов)

**Что в ноутбуке:**
- prompt-разметка отзывов;
- сводные распределения по тональности/аспектам;
- примеры разметки и быстрые срезы по сегментам.

---

## 4) Кластеризация товаров продавца (Embeddings + UMAP + HDBSCAN)

**Файл:** `Кластеризация товаров продавца.ipynb`

**Цель:** сгруппировать карточки товаров по смыслу (для анализа ассортимента/структуры каталога).

**Пайплайн:**
- текстовая подготовка карточек (очистка «маркетплейсного мусора», нормализация);
- эмбеддинги **Sentence-Transformers**
  - модель: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- при необходимости: LLM-обогащение коротких карточек
  - модель: `Qwen/Qwen2.5-0.5B-Instruct`
- понижение размерности:
  - **UMAP** (пространство для кластеризации)
  - **t-SNE** (визуализация)
- кластеризация:
  - **HDBSCAN / DBSCAN**
- визуализация кластеров + интерпретация результатов.

---

## Как запускать

- Для воспроизведения обычно достаточно Python-стека: `pandas`, `numpy`, `scikit-learn`, `matplotlib`.
- Для отдельных ноутбуков дополнительно:
  - `transformers`, `torch` (BERT)
  - `sentence-transformers`, `umap-learn`, `hdbscan` (кластеризация)
  - LLM-части требуют доступной модели/окружения (локально/в облаке).


